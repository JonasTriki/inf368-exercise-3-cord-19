{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Idea\n",
    "1. Get query, e.g. \"What is love?\"\n",
    "2. Tokenize query\n",
    "3. Create a vector using word2vec of the tokens by summing them, or finding the average or whatever.\n",
    "   lets call it the query vector. \n",
    "4. Find sentence vectors that are the closesest to the query vector.\n",
    "5. Return the papers corresponding to said sentence vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import nltk\n",
    "import spacy\n",
    "import en_core_sci_lg # Biomedical word embeddings\n",
    "from utils import clean_text, load_pickle, save_pickle\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from collections.abc import Iterable\n",
    "from typing import Union\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "import pymongo\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re \n",
    "from string import punctuation as PUNCTUATION\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from os.path import join as join_path\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cord-19-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "class DocEpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the last trained model\n",
    "model = Word2Vec.load(join_path('models-word2vec', 'w2v_model_epoch_29.model'))\n",
    "word_to_int = {word:i for i, word in enumerate(model.wv.index2word)}\n",
    "int_to_word = np.array(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning initilized on 16 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning texts: 100%|██████████| 16/16 [00:00<00:00, 101.59it/s]\n",
      "Adding to index: 100%|██████████| 16/16 [00:00<00:00, 322.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import (CordDoc, Index, RecursiveDescentParser, \n",
    "                             AI_Index)\n",
    "\n",
    "ai_index = AI_Index(model.wv.most_similar, n_similars=1)\n",
    "ai_index.build_from_df(\n",
    "    df[:16],\n",
    "    'cord_uid',\n",
    "    'title',\n",
    "    'body_text', \n",
    "    verbose=True, \n",
    "    use_multiprocessing=True,\n",
    "    workers=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1wswi7us  Relationship of SARS-CoV to other pathogenic RNA viruses explored by t  39.6302\n",
      "yy96yeu9  Viral Discovery and Sequence Recovery Using DNA Microarrays             15.6958\n",
      "xqhn0vbp  Airborne rhinovirus detection and effect of ultraviolet irradiation on  10.8963\n",
      "qj4dh6rg  Cloaked similarity between HIV-1 and SARS-CoV suggests an anti-SARS st  8.0116\n",
      "5s6acr7m  The Virus That Changed My World                                         7.2854\n",
      "le0ogx1s  A new recruit for the army of the men of death                          7.0304\n",
      "0qaoam29  A double epidemic model for the SARS propagation                        5.1278\n",
      "gi6uaa83  Discovering human history from stomach bacteria                         2.6177\n",
      "ng4rrdte  Pro/con clinical debate: Steroids are a key component in the treatment  1.9475\n",
      "fy4w7xz8  Association of HLA class I with severe acute respiratory syndrome coro  0.9052\n",
      "1769ovyk  8th Annual Toronto Critical Care Medicine Symposium, 30 October–1 Nove  0.4316\n",
      "kuybfc1y  Descriptive review of geographic mapping of severe acute respiratory s  0.4206\n"
     ]
    }
   ],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import CordDoc, Index, RecursiveDescentParser, AI_Index\n",
    "\n",
    "docs, scores, errmsgs = ai_index.search('virus')\n",
    "\n",
    "n = 69\n",
    "if errmsgs:\n",
    "    print(errmsgs)\n",
    "else:\n",
    "    for doc, score in zip(docs, scores):\n",
    "        print(f'{doc.uid}  {str(doc.title)[:70]:<70}  {score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1769ovyk}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_index.docmap['grace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping qzm9wgde\n"
     ]
    }
   ],
   "source": [
    "with open('textfile.txt', 'w+') as f:\n",
    "    uid = 'qzm9wgde'\n",
    "    \n",
    "    print(f'dumping {uid}')\n",
    "    f.write(df[df.cord_uid == uid].body_text.values[0].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import (CordDoc, Index, RecursiveDescentParser, \n",
    "                             AI_Index)\n",
    "\n",
    "ram_index = AI_Index(model.wv.most_similar, 1)\n",
    "# ram_index.build_from_df(\n",
    "#     df,\n",
    "#     'cord_uid',\n",
    "#     'title',\n",
    "#     'body_text', \n",
    "#     verbose=True, \n",
    "#     use_multiprocessing=True,\n",
    "#     workers=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coordle_mongobackend as cm\n",
    "reload(cm)\n",
    "\n",
    "mongoindex = cm.AI_Index('coordle', model.wv.most_similar, 1)\n",
    "# mongoindex.build_from_df(df, 'cord_uid', 'title', 'body_text', \n",
    "#                          use_multiprocessing=True, workers=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs, scores, errmsgs = ram_index.search('white retarded AND woman')\n",
    "\n",
    "n = 69\n",
    "if errmsgs:\n",
    "    print(errmsgs)\n",
    "else:\n",
    "    for doc, score in zip(docs, scores):\n",
    "        print(f'{doc.uid}   {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36565"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongoindex.wordcounts.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5496\n",
      "1388\n",
      "278\n",
      "503\n",
      "3891\n",
      "598\n",
      "8a348729   nan\n",
      "cd7adns8   nan\n",
      "rv2hrsbo   nan\n",
      "hau0cshe   nan\n",
      "qvn33l36   nan\n",
      "6q4yhekq   nan\n",
      "a6cepu5h   nan\n",
      "xihpfidg   nan\n",
      "cqqumvsb   nan\n",
      "zp9k1k3z   nan\n",
      "l0kc731z   nan\n",
      "vipx6t7e   nan\n",
      "yetd2u2a   nan\n",
      "a714injz   nan\n",
      "vtlf65vq   nan\n",
      "tj3ye1mx   nan\n",
      "cgcvfftf   nan\n",
      "p8no6rc9   nan\n",
      "zotfbuwu   nan\n",
      "cvj9zn0w   nan\n",
      "alm3p31f   nan\n",
      "ru7mvfc0   nan\n",
      "jmifk1q0   nan\n",
      "rz4r5sj7   nan\n",
      "cvqt35ao   nan\n",
      "hxj4z228   nan\n",
      "m1cuuehi   nan\n",
      "rm8d8fyj   nan\n",
      "26su14qs   nan\n",
      "71b0nyti   nan\n",
      "r5mmsnbx   nan\n",
      "pd3vu5y6   nan\n",
      "fed9xg86   nan\n",
      "39vjafky   nan\n",
      "8t3rptw0   nan\n",
      "cqlt5mq2   nan\n",
      "cldrzet3   nan\n",
      "soahaqup   nan\n",
      "epchoupz   nan\n",
      "49oti4zg   nan\n",
      "r73datur   nan\n",
      "0cfafydb   nan\n",
      "lut7vovl   nan\n",
      "lkyvok5t   nan\n",
      "vymlfsdn   nan\n",
      "oofrmpw5   nan\n",
      "ehq9qnoo   nan\n",
      "n8mlxe7p   nan\n",
      "3s4jrkuo   nan\n",
      "0smnl70i   nan\n",
      "rhyrhh01   nan\n",
      "sdz6d1r5   nan\n",
      "4kkjlyky   nan\n",
      "eh21tdhp   nan\n",
      "0am4l5ms   nan\n",
      "1ycn9xwc   nan\n",
      "8xmi0sd4   nan\n",
      "fro63b1z   nan\n",
      "1oudyt9s   nan\n",
      "2u6daypm   nan\n",
      "ihat3yy8   nan\n",
      "rrverrsj   nan\n",
      "jux2xc6i   nan\n",
      "acwkh6ed   nan\n",
      "mludwtgc   nan\n",
      "sar50ej0   nan\n",
      "57ghjur1   nan\n",
      "sit2rhni   nan\n",
      "vsu8njhz   nan\n",
      "el4n88xm   nan\n",
      "v5y3jsgv   nan\n",
      "qzm9wgde   nan\n",
      "dmn53j9d   nan\n",
      "jkh6yj4j   nan\n",
      "e8ofgrgx   nan\n",
      "6cex9gid   nan\n",
      "hwjkbpqp   nan\n",
      "94anrxyw   nan\n",
      "oja9rqcn   nan\n",
      "9q0uvtzk   nan\n",
      "rtg7fs82   nan\n",
      "f9hya0r6   nan\n",
      "2y1y8jpx   nan\n",
      "doagajtl   nan\n",
      "tlcsgoc0   nan\n",
      "wbddg6z5   nan\n",
      "jwm2sqb7   nan\n",
      "zrjx31ev   nan\n",
      "b60knyv7   nan\n",
      "yu7toqw9   nan\n",
      "bv7udg9k   nan\n",
      "33kybfb5   nan\n",
      "7yse6kjd   nan\n",
      "diwwxm6u   nan\n",
      "ammtijql   nan\n",
      "l7rn00vq   nan\n",
      "pjbr6yl2   nan\n",
      "ackvbi1g   nan\n",
      "br8oczw5   nan\n",
      "n6sq2jz9   nan\n",
      "8lwnmdeq   nan\n",
      "k1jq4m35   nan\n",
      "kdoht8np   nan\n",
      "r72jtoso   nan\n",
      "dqa5vdw6   nan\n"
     ]
    }
   ],
   "source": [
    "docs, scores, errmsgs = mongoindex.search('white AND retarded AND woman')\n",
    "\n",
    "n = 69\n",
    "if errmsgs:\n",
    "    print(errmsgs)\n",
    "else:\n",
    "    for doc, score in zip(docs, scores):\n",
    "        print(f'{doc}   {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap = {word:[doc.uid for doc in docs] for word, docs in ai_index.docmap.items() if len(word) < 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'd', 'c'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = pd.value_counts(['a','a','a','d','c','c','c','c','d'], sort=False)\n",
    "A.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[],0]\n",
    "A[0].append(1)\n",
    "A[1] += 1\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<center><h2> Junkyard </h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e4c8e09828d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sets from dicts is faster than from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "dict_time = []\n",
    "list_time = []\n",
    "ratios = []\n",
    "\n",
    "xrange = np.arange(1000,1000000,1000)\n",
    "B = set(list(range(100000)))\n",
    "\n",
    "for j in xrange:\n",
    "    a = list(range(j))\n",
    "\n",
    "    t0=time()\n",
    "    A = set(a)\n",
    "    A | B\n",
    "    t1_list = time()-t0\n",
    "    list_time.append(t1_list)\n",
    "    \n",
    "    a = {i:None for i in range(j)}\n",
    "    \n",
    "    t0=time()\n",
    "#     A = set(a)\n",
    "    a.keys() | B\n",
    "    t1_dict = time()-t0\n",
    "    dict_time.append(t1_dict)\n",
    "\n",
    "    ratios.append(t1_list/t1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xrange[1:], dict_time[1:], label='dict')\n",
    "plt.plot(xrange[1:], list_time[1:], label='list')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xrange[1:], ratios[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import CordDoc, Index2, RecursiveDescentParser, AI_Index2\n",
    "Index = Index2\n",
    "\n",
    "queries = [\n",
    "    'retarded!!!',\n",
    "#     '(',\n",
    "#     ')',\n",
    "    'retarded (white AND (woman NOT man))',\n",
    "    'retarded (white AND white) man',\n",
    "#     'retarded OR white OR woman',\n",
    "#     'retarded white AND woman',\n",
    "#     'retarded OR white NOT woman',\n",
    "#     'retarded (white NOT woman)',\n",
    "#     'retarded (white NOT woman)',\n",
    "#     'OR retarded AND white woman',\n",
    "#     'retarded AND AND white NOT woman',\n",
    "#     'retarded (white NOT woman) AND',\n",
    "#     ')retarded ((white NOT woman) AND',\n",
    "#     'retarded ((white NOT woman)',\n",
    "#     'AND retarded)) ((white NOT woman) NOT',\n",
    "]\n",
    "\n",
    "rdp = RecursiveDescentParser(index.docmap)\n",
    "for query in queries:\n",
    "    errmsgs = []\n",
    "    tokens = rdp.get_logical_querytokens(query)\n",
    "    pass_ = rdp.assert_query(tokens, errmsgs)\n",
    "    \n",
    "#     print(tokens)\n",
    "    print(rdp.parenthesis_handler(tokens))\n",
    "#     print(errmsgs)\n",
    "    print(pass_)\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
