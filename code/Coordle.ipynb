{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Idea\n",
    "1. Get query, e.g. \"What is love?\"\n",
    "2. Tokenize query\n",
    "3. Create a vector using word2vec of the tokens by summing them, or finding the average or whatever.\n",
    "   lets call it the query vector. \n",
    "4. Find sentence vectors that are the closesest to the query vector.\n",
    "5. Return the papers corresponding to said sentence vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import nltk\n",
    "import spacy\n",
    "import en_core_sci_lg # Biomedical word embeddings\n",
    "from utils import clean_text, load_pickle, save_pickle\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from collections.abc import Iterable\n",
    "from typing import Union\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re \n",
    "from string import punctuation as PUNCTUATION\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from os.path import join as join_path\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cord-19-data.csv', nrows=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self, output_dir: str, prefix: str, logs_filename: str):\n",
    "        self.output_dir = output_dir\n",
    "        self.prefix = prefix\n",
    "        self.logs_filename = logs_filename\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        cum_loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            loss = cum_loss\n",
    "        else:\n",
    "            loss = cum_loss - self.loss_previous_step\n",
    "        self.loss_previous_step = loss\n",
    "        with open(join_path(self.output_dir, self.logs_filename), 'a+') as file:\n",
    "            file.write(f'Epoch #{self.epoch}, loss: {loss}\\n')\n",
    "        \n",
    "        output_path = join_path(self.output_dir, f'{self.prefix}_epoch_{self.epoch}.model')\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1\n",
    "\n",
    "class DocEpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self, output_dir: str, prefix: str, start_epoch: int = 1):\n",
    "        self.output_dir = output_dir\n",
    "        self.prefix = prefix\n",
    "        self.epoch = start_epoch\n",
    "\n",
    "    def on_epoch_end(self, model):        \n",
    "        output_path = join_path(self.output_dir, f'{self.prefix}_epoch_{self.epoch}.model')\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the last trained model\n",
    "model = Word2Vec.load(join_path('models-word2vec', 'w2v_model_epoch_29.model'))\n",
    "word_to_int = {word:i for i, word in enumerate(model.wv.index2word)}\n",
    "int_to_word = np.array(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning initilized on 16 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning texts: 100%|██████████| 128/128 [00:03<00:00, 41.05it/s]\n",
      "Adding to index: 100%|██████████| 128/128 [00:00<00:00, 451.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import (CordDoc, Index, RecursiveDescentParser, \n",
    "                             AI_Index, DocWordCounts, WordToDoc)\n",
    "\n",
    "DocWordCounts.objects.delete()\n",
    "WordToDoc.objects.delete()\n",
    "\n",
    "ai_index = AI_Index(model.wv.most_similar, n_similars=1)\n",
    "ai_index.build_from_df(\n",
    "    df.iloc[:128],\n",
    "    'cord_uid',\n",
    "    'title',\n",
    "    'body_text', \n",
    "    verbose=True, \n",
    "    use_multiprocessing=True,\n",
    "    workers=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s6ort9f  Accuracy of parents in measuring body temperature with a tympanic ther  26.7016\n",
      "fy4w7xz8  Association of HLA class I with severe acute respiratory syndrome coro  15.1699\n",
      "1wswi7us  Relationship of SARS-CoV to other pathogenic RNA viruses explored by t  6.4734\n",
      "i948aq4b  A simple and rapid approach for screening of SARS-coronavirus genotype  5.8192\n",
      "ln8ddyuj  Persistence of lung inflammation and lung cytokines with high-resoluti  5.4613\n",
      "jzj8q25c  Proteomics computational analyses suggest that the carboxyl terminal g  5.4006\n",
      "mtmgur1u  Dynamic changes of serum SARS-Coronavirus IgG, pulmonary function and   3.5266\n",
      "jh9e85c0  Molecular mechanisms of severe acute respiratory syndrome (SARS)        2.9878\n",
      "04cuk2cn  Recombinant Tula hantavirus shows reduced fitness but is able to survi  2.9438\n",
      "efrv5nvf  Reference gene selection for quantitative real-time PCR analysis in vi  2.8672\n",
      "i4pmux28  Why can't I visit? The ethics of visitation restrictions – lessons lea  2.8202\n",
      "zc491h8v  Peptide inhibitors of dengue virus and West Nile virus infectivity      2.6684\n",
      "bhlnwu69  Limits to Forecasting Precision for Outbreaks of Directly Transmitted   1.7388\n",
      "rrhh2alf  A human in vitro model system for investigating genome-wide host respo  1.6059\n",
      "kuybfc1y  Descriptive review of geographic mapping of severe acute respiratory s  1.5666\n",
      "0fitbwuv  Molecular advances in the cell biology of SARS-CoV and current disease  1.5082\n",
      "ovpgw054  Molecular signature of clinical severity in recovering patients with s  1.4517\n",
      "xtg0e142  A novel pancoronavirus RT-PCR assay: frequent detection of human coron  1.3735\n",
      "47ema2dq  A systematic review of the effectiveness of antimicrobial rinse-free h  1.3120\n",
      "ej795nks  Understanding the Spatial Clustering of Severe Acute Respiratory Syndr  1.2779\n",
      "ic4d9dhk  Expression profile of immune response genes in patients with Severe Ac  1.2179\n",
      "sgmk96vr  Logistics of community smallpox control through contact tracing and ri  1.1522\n",
      "1769ovyk  8th Annual Toronto Critical Care Medicine Symposium, 30 October–1 Nove  0.8036\n",
      "2vlvz5o9  Design of Wide-Spectrum Inhibitors Targeting Coronavirus Main Protease  0.7599\n",
      "mxyxwkhx  Replicative homeostasis II: Influence of polymerase fidelity on RNA vi  0.6925\n",
      "qzm9wgde  Macrophages and cytokines in the early defence against herpes simplex   0.3778\n",
      "ri5v6u4x  Towards evidence-based, GIS-driven national spatial health information  0.3217\n"
     ]
    }
   ],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import CordDoc, Index, RecursiveDescentParser, AI_Index\n",
    "\n",
    "docs, scores, errmsgs = ai_index.search('fever')\n",
    "\n",
    "n = 69\n",
    "if errmsgs:\n",
    "    print(errmsgs)\n",
    "else:\n",
    "    for doc, score in zip(docs, scores):\n",
    "        print(f'{doc.uid}  {str(doc.title)[:70]:<70}  {score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping qzm9wgde\n"
     ]
    }
   ],
   "source": [
    "with open('textfile.txt', 'w+') as f:\n",
    "    uid = 'qzm9wgde'\n",
    "    \n",
    "    print(f'dumping {uid}')\n",
    "    f.write(df[df.cord_uid == uid].body_text.values[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo\n",
    "\n",
    "Try to insert to database using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = WordToDoc(word='giggolo') \n",
    "temp.uids.extend(['1','2','3'])\n",
    "temp.uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docmap = {word:[doc.uid for doc in docs] for key, docs in ai_index.docmap.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "ValidationError (WordToDoc:giggolo) (StringField only accepts string values 1.StringField only accepts string values: ['uids'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-93969912fbeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordToDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'giggolo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/mongoengine/document.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, force_insert, validate, clean, write_concern, cascade, cascade_kwargs, _refs, save_condition, signal_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrite_concern\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/mongoengine/base/document.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, clean)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ValidationError (%s:%s) \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: ValidationError (WordToDoc:giggolo) (StringField only accepts string values 1.StringField only accepts string values: ['uids'])"
     ]
    }
   ],
   "source": [
    "for word, uids in ai_index.docmap.items():\n",
    "    temp = WordToDoc(word='giggolo')\n",
    "    struids = [uids]\n",
    "    temp.uids.extend(list(uids))\n",
    "    temp.save()\n",
    "    break\n",
    "\n",
    "temp.uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding to DB:   0%|          | 0/21296 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "ValidationError (WordToDoc:10minute) (StringField only accepts string values 1.StringField only accepts string values: ['uids'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e063d5d3f095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordToDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/mongoengine/document.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, force_insert, validate, clean, write_concern, cascade, cascade_kwargs, _refs, save_condition, signal_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrite_concern\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/mongoengine/base/document.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, clean)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ValidationError (%s:%s) \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: ValidationError (WordToDoc:10minute) (StringField only accepts string values 1.StringField only accepts string values: ['uids'])"
     ]
    }
   ],
   "source": [
    "\n",
    "# for word, uids in tqdm(ai_index.docmap.items(), desc='Adding to DB',\n",
    "#                                total=len(ai_index.docmap), position=0):\n",
    "#     if len(word) < 500:\n",
    "#         temp = WordToDoc(word=word)\n",
    "#         temp.uids.extend(list(uids))\n",
    "#         temp.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import CordDoc, Index2, RecursiveDescentParser, AI_Index2\n",
    "Index = Index2\n",
    "\n",
    "queries = [\n",
    "    'retarded!!!',\n",
    "#     '(',\n",
    "#     ')',\n",
    "    'retarded (white AND (woman NOT man))',\n",
    "    'retarded (white AND white) man',\n",
    "#     'retarded OR white OR woman',\n",
    "#     'retarded white AND woman',\n",
    "#     'retarded OR white NOT woman',\n",
    "#     'retarded (white NOT woman)',\n",
    "#     'retarded (white NOT woman)',\n",
    "#     'OR retarded AND white woman',\n",
    "#     'retarded AND AND white NOT woman',\n",
    "#     'retarded (white NOT woman) AND',\n",
    "#     ')retarded ((white NOT woman) AND',\n",
    "#     'retarded ((white NOT woman)',\n",
    "#     'AND retarded)) ((white NOT woman) NOT',\n",
    "]\n",
    "\n",
    "rdp = RecursiveDescentParser(index.docmap)\n",
    "for query in queries:\n",
    "    errmsgs = []\n",
    "    tokens = rdp.get_logical_querytokens(query)\n",
    "    pass_ = rdp.assert_query(tokens, errmsgs)\n",
    "    \n",
    "#     print(tokens)\n",
    "    print(rdp.parenthesis_handler(tokens))\n",
    "#     print(errmsgs)\n",
    "    print(pass_)\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
