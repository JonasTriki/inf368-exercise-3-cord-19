{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Idea\n",
    "1. Get query, e.g. \"What is love?\"\n",
    "2. Tokenize query\n",
    "3. Create a vector using word2vec of the tokens by summing them, or finding the average or whatever.\n",
    "   lets call it the query vector. \n",
    "4. Find sentence vectors that are the closesest to the query vector.\n",
    "5. Return the papers corresponding to said sentence vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Frontend\n",
    "ðŸ’©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordle Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import nltk\n",
    "import spacy\n",
    "import en_core_sci_lg # Biomedical word embeddings\n",
    "from utils import clean_text, load_pickle, save_pickle\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from collections.abc import Iterable\n",
    "from typing import Union\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re \n",
    "from string import punctuation as PUNCTUATION\n",
    "from nltk.corpus import stopwords as _stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from os.path import join as join_path\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cord-19-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cord_uid', 'paper_id', 'source', 'is_pmc', 'title', 'body_text', 'doi',\n",
       "       'pubmed_id', 'license', 'abstract', 'publish_time', 'authors',\n",
       "       'journal', 'url', 'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self, output_dir: str, prefix: str, logs_filename: str):\n",
    "        self.output_dir = output_dir\n",
    "        self.prefix = prefix\n",
    "        self.logs_filename = logs_filename\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        cum_loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            loss = cum_loss\n",
    "        else:\n",
    "            loss = cum_loss - self.loss_previous_step\n",
    "        self.loss_previous_step = loss\n",
    "        with open(join_path(self.output_dir, self.logs_filename), 'a+') as file:\n",
    "            file.write(f'Epoch #{self.epoch}, loss: {loss}\\n')\n",
    "        \n",
    "        output_path = join_path(self.output_dir, f'{self.prefix}_epoch_{self.epoch}.model')\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1    \n",
    "\n",
    "class DocEpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self, output_dir: str, prefix: str, start_epoch: int = 1):\n",
    "        self.output_dir = output_dir\n",
    "        self.prefix = prefix\n",
    "        self.epoch = start_epoch\n",
    "\n",
    "    def on_epoch_end(self, model):        \n",
    "        output_path = join_path(self.output_dir, f'{self.prefix}_epoch_{self.epoch}.model')\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the last trained model\n",
    "model = Word2Vec.load(join_path('models-word2vec', 'w2v_model_epoch_29.model'))\n",
    "word_to_int = {word:i for i, word in enumerate(model.wv.index2word)}\n",
    "int_to_word = np.array(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Word2Vec.load(join_path('models-doc2vec', 'model_epoch_9.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ability\n",
      "\n",
      "[('able', 0.7927937507629395),\n",
      " ('abilities', 0.7574480175971985),\n",
      " ('capability', 0.7555814981460571),\n",
      " ('capacity', 0.713545024394989),\n",
      " ('inability', 0.6850271224975586),\n",
      " ('unable', 0.6693112850189209),\n",
      " ('could', 0.6653134822845459),\n",
      " ('effectively', 0.6319371461868286),\n",
      " ('efficiently', 0.5879989862442017),\n",
      " ('importantly', 0.5701096057891846)]\n",
      "\n",
      "[('capability', 0.7155430912971497),\n",
      " ('capacity', 0.6828085780143738),\n",
      " ('inability', 0.650448203086853),\n",
      " ('able', 0.5796688795089722),\n",
      " ('unable', 0.5606363415718079),\n",
      " ('propensity', 0.524204671382904),\n",
      " ('tendency', 0.48691150546073914),\n",
      " ('proclivity', 0.47566479444503784),\n",
      " ('failed', 0.4682592451572418),\n",
      " ('wishing', 0.4622066020965576)]\n"
     ]
    }
   ],
   "source": [
    "word = clean_text('abilities', return_list=False)\n",
    "print(word)\n",
    "print()\n",
    "pprint(model.wv.most_similar(word))\n",
    "print()\n",
    "pprint(model2.wv.most_similar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning initilized on 16 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning texts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:15<00:00, 258.14it/s]\n",
      "Adding to index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:22<00:00, 180.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import SentVectorDoc, Index\n",
    "\n",
    "docsample = df.iloc[0]\n",
    "def test_SentVectorDoc():\n",
    "    doc = SentVectorDoc(docsample['cord_uid'], docsample['title'])\n",
    "    doc, _ = doc.fit(docsample['body_text'])\n",
    "    print(doc.tf_idf_score)\n",
    "    return doc\n",
    "\n",
    "def test_Index():\n",
    "    coordle = Index()\n",
    "    for i in tqdm(range(1024), position=0):\n",
    "        sample = df.iloc[i]\n",
    "        coordle.add(sample['cord_uid'], sample['title'], sample['body_text'])\n",
    "    return coordle\n",
    "\n",
    "def test_Index2():\n",
    "    coordle = Index()\n",
    "    coordle.build_from_df(\n",
    "        df.iloc[:4096],\n",
    "        'cord_uid',\n",
    "        'title',\n",
    "        'body_text', \n",
    "        verbose=True, \n",
    "        use_multiprocessing=True,\n",
    "        workers=-1\n",
    "    )\n",
    "    return coordle\n",
    "\n",
    "index = test_Index2()\n",
    "# fuck = test_SentVectorDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query tokens:  ['retarded', 'white', 'woman']\n",
      "\n",
      "iwueedmm   Post-traumatic stress disorder among Chinese women survivors of intimate partner   2.0220\n",
      "alm3p31f   Chapter 3 Immunobiological aspects of vaccines in pregnancy: Maternal perspectiv   1.4323\n",
      "94anrxyw   Chapter 47 Infections in Pregnancy                                                 1.2428\n",
      "8p4t1dr6   Emergency Caesarean delivery in a patient with confirmed coronavirus disease 201   0.8291\n",
      "ibrvg7rd   88 Gender-Specific Issues in Non-HIV Viral Infections                              0.7680\n",
      "xfr3cyql   Chapter 10 Respiratory syncytial virus                                             0.7319\n",
      "vq0p5d2x   nan                                                                                0.6711\n",
      "v0gngwzx   Pregnancy and perinatal outcomes of women with severe acute respiratory syndrome   0.6644\n",
      "wnf8fozk   5.16 Infections in Pregnancyâ˜†                                                      0.6100\n",
      "2zfrogg9   Hypoxia-like tissue injury as a component of multiple sclerosis lesions            0.6011\n",
      "yjodgy2v   A stochastic SIRS epidemic model with non-monotone incidence rate under regime-s   0.5915\n",
      "7xef0hdr   96 The Lungs in Obstetric and Gynecologic Diseases                                 0.5812\n",
      "rtqkvf63   2.6 Anti-infective Agents                                                          0.5650\n",
      "ocwggg9f   In vivo and in vitro models of demyelinating disease. XVII. The infectious proce   0.5512\n",
      "w5r96iq3   Human coronavirus gene expression in the brains of multiple sclerosis patients     0.5303\n",
      "6rhyy4pw   Chapter 1 Exercise and infection risk                                              0.5209\n"
     ]
    }
   ],
   "source": [
    "docs, scores = index.search('retarded white woman', verbose=True)\n",
    "n = 16\n",
    "print()\n",
    "for doc, score in zip(docs[:n], scores[:n]):\n",
    "    print(f'{doc.uid}   {str(doc.title)[:80]:<80}   {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning initilized on 16 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning texts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4096/4096 [00:18<00:00, 224.97it/s]\n",
      "Adding to index:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1524/4096 [00:10<00:18, 137.43it/s]"
     ]
    }
   ],
   "source": [
    "import coordle_backend\n",
    "reload(coordle_backend)\n",
    "from coordle_backend import SentVectorDoc, Index, AI_Index\n",
    "\n",
    "def test_AI_Index(model):\n",
    "    coordle = AI_Index(model.wv.most_similar, 3)\n",
    "    coordle.build_from_df(\n",
    "        df.iloc[:4096],\n",
    "        'cord_uid',\n",
    "        'title',\n",
    "        'body_text',\n",
    "        use_multiprocessing=True,\n",
    "        workers=-1,\n",
    "        verbose=True\n",
    "    )\n",
    "    return coordle\n",
    "\n",
    "ai_index = test_AI_Index(model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query tokens:  ['retarded', 'white', 'woman', 'girl', '52yearold', '59yearold', 'gray', 'red', 'graywhite', 'retardation', 'diminished', 'reduced']\n",
      "\n",
      "cmat0grk   Chapter 15 Captive Red Panda Medicine                                              0.7252\n",
      "iwueedmm   Post-traumatic stress disorder among Chinese women survivors of intimate partner   0.7100\n",
      "alm3p31f   Chapter 3 Immunobiological aspects of vaccines in pregnancy: Maternal perspectiv   0.5522\n",
      "94anrxyw   Chapter 47 Infections in Pregnancy                                                 0.4715\n",
      "f33fzent   Avian Infectious Bronchitis Virus                                                  0.4588\n",
      "2qg9vuvd   Chapter 3 Blood Vital but Potentially Dangerous                                    0.4164\n",
      "8p4t1dr6   Emergency Caesarean delivery in a patient with confirmed coronavirus disease 201   0.3904\n",
      "w5r96iq3   Human coronavirus gene expression in the brains of multiple sclerosis patients     0.3410\n",
      "w232rzi9   Chapter 132 Utilizing Blood Bank Resources/Transfusion Reactions and Complicatio   0.3197\n",
      "ibrvg7rd   88 Gender-Specific Issues in Non-HIV Viral Infections                              0.3093\n",
      "xihpfidg   11 Social, cultural, and other diversity issues in the traumatic stress field      0.2989\n",
      "9olk4czm   Association of angiotensin-converting enzyme 2 gene A/G polymorphism and elevate   0.2925\n",
      "fx7c22fj   Experimental demyelination induced by coronavirus JHM (MHV-4): molecular identif   0.2899\n",
      "pk960yfx   Clinical Transfusion Medicine                                                      0.2830\n",
      "qkysu5dv   23 Approach to the Diagnosis and Classification of Blood Cell Disorders            0.2718\n",
      "yx0busge   Chapter 49 Procyonids and Viverids                                                 0.2680\n"
     ]
    }
   ],
   "source": [
    "docs, scores = ai_index.search('retarded white woman', verbose=True)\n",
    "n = 16\n",
    "print()\n",
    "for doc, score in zip(docs[:n], scores[:n]):\n",
    "    print(f'{doc.uid}   {doc.title[:80]:<80}   {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing showdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33554/33554 [01:19<00:00, 420.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning with multiprocessing took 81.86 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "with Pool(None) as p:\n",
    "    cleaned_texts = list(tqdm(p.imap(clean_text, df.body_text), position=0, total=len(df)))\n",
    "print(f'Text cleaning with multiprocessing took {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33554/33554 [10:38<00:00, 52.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaÃ¯ve text cleaning took 640.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "gen = tqdm((clean_text(text) for text in df.body_text), position=0, total=len(df))\n",
    "cleaned_texts = list(gen)\n",
    "print(f'NaÃ¯ve text cleaning took {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:07<00:00, 268.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning with multiprocessing took 12.61 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "with Pool(None) as p:\n",
    "    cleaned_texts = list(tqdm(p.imap(clean_text, df.body_text[:2048]), position=0, total=2048))\n",
    "print(f'Text cleaning with multiprocessing took {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:54<00:00, 37.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaÃ¯ve text cleaning took 54.70 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "gen = tqdm((clean_text(text) for text in df.body_text[:2048]), position=0, total=2048)\n",
    "cleaned_texts = list(gen)\n",
    "print(f'NaÃ¯ve text cleaning took {time()-t0:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
